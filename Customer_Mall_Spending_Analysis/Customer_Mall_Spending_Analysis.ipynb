{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe766189-e685-4155-8303-2d8466ff92f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home\"\n",
    "print(os.environ[\"JAVA_HOME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "913bf5cd-e080-4d61-a942-4a77e530ba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Java Virtual Machines (3):\n",
      "    24.0.1 (arm64) \"Oracle Corporation\" - \"Java SE 24.0.1\" /Library/Java/JavaVirtualMachines/jdk-24.jdk/Contents/Home\n",
      "    21.0.7 (arm64) \"Homebrew\" - \"OpenJDK 21.0.7\" /opt/homebrew/Cellar/openjdk@21/21.0.7/libexec/openjdk.jdk/Contents/Home\n",
      "    11.0.27 (arm64) \"Homebrew\" - \"OpenJDK 11.0.27\" /opt/homebrew/Cellar/openjdk@11/11.0.27/libexec/openjdk.jdk/Contents/Home\n",
      "/Library/Java/JavaVirtualMachines/jdk-24.jdk/Contents/Home\n"
     ]
    }
   ],
   "source": [
    "!/usr/libexec/java_home -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf3e4f-bd6d-4065-9e5d-080328bd3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step: 1 - Load Dataset in Jupyter Notebook#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2036d87-e6cb-4ca6-918a-9961e6ba8bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spark in /opt/anaconda3/lib/python3.12/site-packages (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1dd3d79-c1f2-4eab-aa62-a87d29338173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/anaconda3/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in /opt/anaconda3/lib/python3.12/site-packages (from pyspark) (0.10.9.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce7fada8-cc69-4454-a5c2-f2317f2326b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CustomerID   Genre  Age  Annual Income (k$)  Spending Score (1-100)\n",
      "0             1    Male   19                  15                      39\n",
      "1             2    Male   21                  15                      81\n",
      "2             3  Female   20                  16                       6\n",
      "3             4  Female   23                  16                      77\n",
      "4             5  Female   31                  17                      40\n",
      "..          ...     ...  ...                 ...                     ...\n",
      "195         196  Female   35                 120                      79\n",
      "196         197  Female   45                 126                      28\n",
      "197         198    Male   32                 126                      74\n",
      "198         199    Male   32                 137                      18\n",
      "199         200    Male   30                 137                      83\n",
      "\n",
      "[200 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/akbarbasha/Desktop/Customer mall projects/Mall_Customers.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8a638-c5d0-46eb-8f82-4ee0dcfc97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step:2:start pyspark session #Before setting up spark. we need verify if spark java version is set to 17 version\n",
    "#setting java variable explicitly to Java 11/17 as it is compatible with spark4.0 session #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa763def-7d63-42a0-a282-5c8f27d13b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(os.environ.get(\"JAVA_HOME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce02989-cf10-4aa3-8304-bd31107d4048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirming and saving the jupyter notebook java variable to 11 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4499f95-e4bf-4873-9b16-fe855f1ccadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"17.0.15\" 2025-04-15\n",
      "OpenJDK Runtime Environment Homebrew (build 17.0.15+0)\n",
      "OpenJDK 64-Bit Server VM Homebrew (build 17.0.15+0, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "!$JAVA_HOME/bin/java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800bbee2-77a6-48a2-8a09-aa72bea296ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System wide java version which is default java version set up of the systems #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "10f8859a-349a-4915-9706-a22e414aafd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"21.0.7\" 2025-04-15\n",
      "OpenJDK Runtime Environment Homebrew (build 21.0.7)\n",
      "OpenJDK 64-Bit Server VM Homebrew (build 21.0.7, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743aa9e0-b0b4-424b-9190-e03b5f3ddcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step:3 -Initalzie spark session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44877ced-4bc6-4245-b7c4-fdd91dcd7ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/09/12 19:21:12 WARN Utils: Your hostname, Akbars-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 192.168.1.6 instead (on interface en0)\n",
      "25/09/12 19:21:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/12 19:21:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MallCustomerAnalysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3124958-3a63-4c19-be54-84c86a81786e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Genre: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Annual Income (k$): integer (nullable = true)\n",
      " |-- Spending Score (1-100): integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.read.csv(\"/Users/akbarbasha/Desktop/Customer mall projects/mall_customers.csv\", header=True, inferSchema=True)\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0edfdcea-3638-46b2-8e51-8430dd1242d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+------------------+----------------------+\n",
      "|CustomerID| Genre|Age|Annual Income (k$)|Spending Score (1-100)|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "|         1|  Male| 19|                15|                    39|\n",
      "|         2|  Male| 21|                15|                    81|\n",
      "|         3|Female| 20|                16|                     6|\n",
      "|         4|Female| 23|                16|                    77|\n",
      "|         5|Female| 31|                17|                    40|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "74e017ba-bb13-450d-97a9-e464f4fbf0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Genre: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Annual Income (k$): integer (nullable = true)\n",
      " |-- Spending Score (1-100): integer (nullable = true)\n",
      "\n",
      "+----------+------+---+------------------+----------------------+\n",
      "|CustomerID| Genre|Age|Annual Income (k$)|Spending Score (1-100)|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "|         1|  Male| 19|                15|                    39|\n",
      "|         2|  Male| 21|                15|                    81|\n",
      "|         3|Female| 20|                16|                     6|\n",
      "|         4|Female| 23|                16|                    77|\n",
      "|         5|Female| 31|                17|                    40|\n",
      "|         6|Female| 22|                17|                    76|\n",
      "|         7|Female| 35|                18|                     6|\n",
      "|         8|Female| 23|                18|                    94|\n",
      "|         9|  Male| 64|                19|                     3|\n",
      "|        10|Female| 30|                19|                    72|\n",
      "|        11|  Male| 67|                19|                    14|\n",
      "|        12|Female| 35|                19|                    99|\n",
      "|        13|Female| 58|                20|                    15|\n",
      "|        14|Female| 24|                20|                    77|\n",
      "|        15|  Male| 37|                20|                    13|\n",
      "|        16|  Male| 22|                20|                    79|\n",
      "|        17|Female| 35|                21|                    35|\n",
      "|        18|  Male| 20|                21|                    66|\n",
      "|        19|  Male| 52|                23|                    29|\n",
      "|        20|Female| 35|                23|                    98|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "+----------+-----+---+------------------+----------------------+\n",
      "|CustomerID|Genre|Age|Annual Income (k$)|Spending Score (1-100)|\n",
      "+----------+-----+---+------------------+----------------------+\n",
      "+----------+-----+---+------------------+----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Cleaning Steps (PySpark)#\n",
    "\n",
    "#1.Verify datatypes\n",
    "spark_df.printSchema()\n",
    "\n",
    "#2.Rename/Normalize Column names\n",
    "spark_df.withColumnRenamed(\"Annual Income (k$)\", \"Annual_Income\") \\\n",
    "        .withColumnRenamed(\"Spending Score (1-100)\", \"Spending_Score\")\n",
    "\n",
    "#3.#Show rows with any isNull()/isNotNull values\n",
    "from pyspark.sql.functions import col\n",
    "spark_df.filter(spark_df[\"Genre\"].isNotNull()).show()\n",
    "spark_df.filter(spark_df[\"Genre\"].isNull()).show()\n",
    "\n",
    "#4.#Count rows with nulls in a specific column\n",
    "spark_df.filter(col(\"Age\").isNull()).count()\n",
    "\n",
    "#5.Fill missing values\n",
    "spark_df = spark_df.na.fill({\"Age\": 0})\n",
    "\n",
    "#6.drop duplicates based on specific columns:\n",
    "spark_df = spark_df.dropDuplicates([\"CustomerID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b69ab18b-ee1d-4daf-a4fb-25214bace3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/11 22:59:17 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------+-----------------+------------------+----------------------+\n",
      "|summary|        CustomerID| Genre|              Age|Annual Income (k$)|Spending Score (1-100)|\n",
      "+-------+------------------+------+-----------------+------------------+----------------------+\n",
      "|  count|               200|   200|              200|               200|                   200|\n",
      "|   mean|             100.5|  NULL|            38.85|             60.56|                  50.2|\n",
      "| stddev|57.879184513951124|  NULL|13.96900733155888| 26.26472116527124|    25.823521668370173|\n",
      "|    min|                 1|Female|               18|                15|                     1|\n",
      "|    max|               200|  Male|               70|               137|                    99|\n",
      "+-------+------------------+------+-----------------+------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Descriptive Statstics#\n",
    "spark_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58528989-9430-4d81-a378-17cf7e391f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+------------------+----------------------+\n",
      "|CustomerID| Genre|Age|Annual Income (k$)|Spending Score (1-100)|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "|         9|  Male| 64|                19|                     3|\n",
      "|        11|  Male| 67|                19|                    14|\n",
      "|        13|Female| 58|                20|                    15|\n",
      "|        19|  Male| 52|                23|                    29|\n",
      "|        23|Female| 46|                25|                     5|\n",
      "|        25|Female| 54|                28|                    14|\n",
      "|        27|Female| 45|                28|                    32|\n",
      "|        31|  Male| 60|                30|                     4|\n",
      "|        33|  Male| 53|                33|                     4|\n",
      "|        35|Female| 49|                33|                    14|\n",
      "|        37|Female| 42|                34|                    17|\n",
      "|        41|Female| 65|                38|                    35|\n",
      "|        43|  Male| 48|                39|                    36|\n",
      "|        45|Female| 49|                39|                    28|\n",
      "|        47|Female| 50|                40|                    55|\n",
      "|        51|Female| 49|                42|                    52|\n",
      "|        54|  Male| 59|                43|                    60|\n",
      "|        55|Female| 50|                43|                    45|\n",
      "|        56|  Male| 47|                43|                    41|\n",
      "|        57|Female| 51|                44|                    50|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "#PySpark Data Transformations#\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "#1.Filter transformation.\n",
    "spark_df.filter(spark_df.Age>40).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "254026bd-0cc1-495e-b47e-7cc894d8ea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+------------------+----------------------+\n",
      "|CustomerID| Genre|Age|Annual Income (k$)|Spending Score (1-100)|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "|        34|  Male| 18|                33|                    92|\n",
      "|        66|  Male| 18|                48|                    59|\n",
      "|        92|  Male| 18|                59|                    41|\n",
      "|       115|Female| 18|                65|                    48|\n",
      "|         1|  Male| 19|                15|                    39|\n",
      "|        62|  Male| 19|                46|                    55|\n",
      "|        69|  Male| 19|                48|                    59|\n",
      "|       112|Female| 19|                63|                    54|\n",
      "|       114|  Male| 19|                64|                    46|\n",
      "|       116|Female| 19|                65|                    50|\n",
      "|       139|  Male| 19|                74|                    10|\n",
      "|       163|  Male| 19|                81|                     5|\n",
      "|         3|Female| 20|                16|                     6|\n",
      "|        18|  Male| 20|                21|                    66|\n",
      "|        40|Female| 20|                37|                    75|\n",
      "|       100|  Male| 20|                61|                    49|\n",
      "|       135|  Male| 20|                73|                     5|\n",
      "|         2|  Male| 21|                15|                    81|\n",
      "|        32|Female| 21|                30|                    73|\n",
      "|        36|Female| 21|                33|                    81|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "#2.Sorting\n",
    "spark_df.orderBy(\"Age\", \"Annual Income (k$)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b9e4f64-9e13-4f68-8aff-dae3e12403aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.Show distinct values\n",
    "spark_df.select(\"Annual Income (k$)\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45232562-3c13-46ec-9660-5a441dec9820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+------------------+----------------------+\n",
      "|CustomerID| Genre|Age|Annual Income (k$)|Spending Score (1-100)|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "|       200|  Male| 30|               137|                    83|\n",
      "|       199|  Male| 32|               137|                    18|\n",
      "|       197|Female| 45|               126|                    28|\n",
      "|       198|  Male| 32|               126|                    74|\n",
      "|       195|Female| 47|               120|                    16|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4.Limit function to show top records\n",
    "spark_df.orderBy(F.col(\"Annual Income (k$)\").desc()).limit(5).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c0d11dce-41d0-4447-922d-46f540b91aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "| Genre|MaxAge|\n",
      "+------+------+\n",
      "|Female|    68|\n",
      "|  Male|    70|\n",
      "+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#5.Groupby and Aggregaton of Gender+Age\n",
    "spark_df.groupBy(\"Genre\").agg(F.max(\"Age\").alias(\"MaxAge\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a5955-1305-475c-9b67-cf63b25a30b3",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    "Analysis report on the basis of the spending score \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "57ec2486-a980-467d-ace1-a4b05d5cdf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------+\n",
      "|summary|Spending Score (1-100)|\n",
      "+-------+----------------------+\n",
      "|  count|                   200|\n",
      "|   mean|                  50.2|\n",
      "| stddev|    25.823521668370173|\n",
      "|    min|                     1|\n",
      "|    max|                    99|\n",
      "+-------+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#1.summary statstics od spending score#\n",
    "spark_df.select(\"Spending Score (1-100)\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc0e6e5b-cc81-4ec8-bad4-6e79e458de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Categorize customers based on the spends\n",
    "from pyspark.sql.functions import when, col\n",
    "spark_df = spark_df.withColumn(\"Spending_Category\",\n",
    "                               when(col(\"Spending Score (1-100)\") <= 40, \"Low Spender\")\n",
    "                               .when((col(\"Spending Score (1-100)\") > 40) & (col(\"Spending Score (1-100)\") <= 70), \"Medium Spender\")\n",
    "                                .otherwise(\"High Spender\")\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d651546e-befb-4929-a439-603ef007de03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|Spending_Category|count|\n",
      "+-----------------+-----+\n",
      "|   Medium Spender|   83|\n",
      "|     High Spender|   54|\n",
      "|      Low Spender|   63|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupBy(\"Spending_Category\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ded8f06-b356-4deb-a528-e408d21627fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------------+\n",
      "| Genre|avg(Spending Score (1-100))|\n",
      "+------+---------------------------+\n",
      "|Female|         51.526785714285715|\n",
      "|  Male|          48.51136363636363|\n",
      "+------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.Spending score by Gender\n",
    "spark_df.groupBy(\"Genre\").avg(\"Spending Score (1-100)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9d117fa-033e-4c18-b3e7-7cf4685d97da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------------------+\n",
      "|Annual Income (k$)|avg(Spending Score (1-100))|\n",
      "+------------------+---------------------------+\n",
      "|                15|                       60.0|\n",
      "|                16|                       41.5|\n",
      "|                17|                       58.0|\n",
      "|                18|                       50.0|\n",
      "|                19|                       47.0|\n",
      "+------------------+---------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "#4.Top 5 Average spending score per Income#\n",
    "spark_df.groupBy(\"Annual Income (k$)\").avg(\"Spending Score (1-100)\").orderBy(\"Annual Income (k$)\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "15598c7f-46cf-49da-a134-7d8c7fe62e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------------+\n",
      "|Age|avg(Spending Score (1-100))|\n",
      "+---+---------------------------+\n",
      "| 18|                       60.0|\n",
      "| 19|                      39.75|\n",
      "| 20|                       40.2|\n",
      "| 21|                       66.8|\n",
      "| 22|                       70.0|\n",
      "| 23|         63.333333333333336|\n",
      "| 24|                       71.5|\n",
      "| 25|         39.666666666666664|\n",
      "| 26|                       54.5|\n",
      "| 27|         60.333333333333336|\n",
      "| 28|                       70.0|\n",
      "| 29|                       76.6|\n",
      "| 30|          80.28571428571429|\n",
      "| 31|                     63.875|\n",
      "| 32|                       66.0|\n",
      "| 33|         54.333333333333336|\n",
      "| 34|                       39.2|\n",
      "| 35|         63.888888888888886|\n",
      "| 36|                       52.5|\n",
      "| 37|         15.333333333333334|\n",
      "+---+---------------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "#5.Avergae spending score as per Age\n",
    "spark_df.groupBy(\"Age\").avg(\"Spending Score (1-100)\").orderBy(\"Age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c5cd3eb2-1a7f-451e-b23e-eed7a7f07379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.select(\"Age\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed398ecc-715f-478c-9ee4-501ceb7ea803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+------------------+----------------------+-----------------+\n",
      "|CustomerID| Genre|Age|Annual Income (k$)|Spending Score (1-100)|Spending_Category|\n",
      "+----------+------+---+------------------+----------------------+-----------------+\n",
      "|        12|Female| 35|                19|                    99|     High Spender|\n",
      "|        20|Female| 35|                23|                    98|     High Spender|\n",
      "|       146|  Male| 28|                77|                    97|     High Spender|\n",
      "|       186|  Male| 30|                99|                    97|     High Spender|\n",
      "|       128|  Male| 40|                71|                    95|     High Spender|\n",
      "|       168|Female| 33|                86|                    95|     High Spender|\n",
      "|         8|Female| 23|                18|                    94|     High Spender|\n",
      "|       142|  Male| 32|                75|                    93|     High Spender|\n",
      "|       164|Female| 31|                81|                    93|     High Spender|\n",
      "|        42|  Male| 24|                38|                    92|     High Spender|\n",
      "+----------+------+---+------------------+----------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6.Top 10 customers by spending score\n",
    "from pyspark.sql import functions as F\n",
    "spark_df.orderBy(F.desc(\"Spending Score (1-100)\")).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a58a28b-a017-45ac-bd67-261b8d0f07a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "|Age|Top_Score|\n",
      "+---+---------+\n",
      "| 18|       92|\n",
      "| 19|       59|\n",
      "| 20|       75|\n",
      "| 21|       81|\n",
      "| 22|       79|\n",
      "| 23|       94|\n",
      "| 24|       92|\n",
      "| 25|       73|\n",
      "| 26|       55|\n",
      "| 27|       89|\n",
      "| 28|       97|\n",
      "| 29|       88|\n",
      "| 30|       97|\n",
      "| 31|       93|\n",
      "| 32|       93|\n",
      "| 33|       95|\n",
      "| 34|       90|\n",
      "| 35|       99|\n",
      "| 36|       92|\n",
      "| 37|       32|\n",
      "+---+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "#7.Top spender per Age group\n",
    "spark_df.groupBy(\"Age\").agg(F.max(\"Spending Score (1-100)\").alias(\"Top_Score\")).orderBy(\"Age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d144d5b6-83d8-4992-b7b2-52c4992f9c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+------------------+----------------------+-----------------+\n",
      "|CustomerID| Genre|Age|Annual Income (k$)|Spending Score (1-100)|Spending_Category|\n",
      "+----------+------+---+------------------+----------------------+-----------------+\n",
      "|        12|Female| 35|                19|                    99|     High Spender|\n",
      "|        20|Female| 35|                23|                    98|     High Spender|\n",
      "|       146|  Male| 28|                77|                    97|     High Spender|\n",
      "|       186|  Male| 30|                99|                    97|     High Spender|\n",
      "|       128|  Male| 40|                71|                    95|     High Spender|\n",
      "|       168|Female| 33|                86|                    95|     High Spender|\n",
      "|         8|Female| 23|                18|                    94|     High Spender|\n",
      "|       142|  Male| 32|                75|                    93|     High Spender|\n",
      "|       164|Female| 31|                81|                    93|     High Spender|\n",
      "|        42|  Male| 24|                38|                    92|     High Spender|\n",
      "+----------+------+---+------------------+----------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#8.Top 10 customers by spending score\n",
    "spark_df.orderBy(F.desc(\"Spending Score (1-100)\")).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2a66b8bc-1b06-4ee5-84ca-9ec86e3b0118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+\n",
      "|Age|Max_Score|Min_Score|\n",
      "+---+---------+---------+\n",
      "| 31|       93|       40|\n",
      "| 65|       52|       35|\n",
      "| 53|       46|        4|\n",
      "| 34|       90|        1|\n",
      "| 28|       97|       40|\n",
      "| 27|       89|       47|\n",
      "| 26|       55|       54|\n",
      "| 44|       20|        7|\n",
      "| 22|       79|       55|\n",
      "| 47|       47|        9|\n",
      "| 52|       29|       13|\n",
      "| 20|       75|        5|\n",
      "| 40|       95|       13|\n",
      "| 57|       51|        5|\n",
      "| 54|       59|       14|\n",
      "| 48|       49|       36|\n",
      "| 19|       59|        5|\n",
      "| 64|        3|        3|\n",
      "| 41|       39|       17|\n",
      "| 43|       50|       17|\n",
      "+---+---------+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "#9.Maximum & Minimum spending score by Age\n",
    "spark_df.groupBy(\"Age\").agg(F.max(\"Spending Score (1-100)\").alias(\"Max_Score\"), F.min(\"Spending Score (1-100)\").alias(\"Min_Score\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb0431ba-6d8c-4701-b63a-300a88413608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Age and Spending Score: -0.32722684603909025\n"
     ]
    }
   ],
   "source": [
    "#10.Find correlation between Spending Score and Age\n",
    "correlation = spark_df.stat.corr(\"Age\", \"Spending Score (1-100)\")\n",
    "print(f\"Correlation between Age and Spending Score: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af1ff4-8919-49e0-9641-baebad5fe661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b4381-68fc-4588-99b2-e91e1f2dd723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b232d862-3a16-4d3c-ab2b-f039f5bfced2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378078cb-c0ac-476b-9b6d-ce3d9fc0d96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a40f40e-ef17-4c2f-a7af-7a239d6ac674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ebe34-0d0a-405b-9937-63a08a97ebba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
