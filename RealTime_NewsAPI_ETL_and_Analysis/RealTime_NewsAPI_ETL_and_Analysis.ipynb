{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Real-Time NewsAPI ETL & Analysis\n",
                "\n",
                "## Project Overview\n",
                "This project demonstrates a real-time ETL (Extract, Transform, Load) pipeline that fetches live news data from **NewsAPI**, transforms it using **Pandas**, loads it into a **PostgreSQL** database, and performs basic analysis.\n",
                "\n",
                "## Tech Stack\n",
                "- **Source**: NewsAPI (REST API)\n",
                "- **Processing**: Python (Pandas)\n",
                "- **Storage**: PostgreSQL\n",
                "- **Visualization**: Matplotlib/Seaborn\n",
                "\n",
                "---\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages (run once)\n",
                "!pip install -q requests pandas sqlalchemy psycopg2-binary matplotlib seaborn\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuration\n",
                "Load API keys and database credentials securely from environment variables.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import requests\n",
                "import pandas as pd\n",
                "from sqlalchemy import create_engine\n",
                "\n",
                "# API Configuration\n",
                "API_KEY = os.getenv(\"NEWS_API_KEY\", \"your_api_key_here\")\n",
                "BASE_URL = \"https://newsapi.org/v2/top-headlines\"\n",
                "\n",
                "# Database Configuration\n",
                "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
                "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
                "DB_NAME = os.getenv(\"DB_NAME\", \"newsdb\")\n",
                "DB_USER = os.getenv(\"DB_USER\", \"postgres\")\n",
                "DB_PASS = os.getenv(\"DB_PASS\", \"password\")\n",
                "\n",
                "# Create DB Connection\n",
                "connection_uri = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
                "engine = create_engine(connection_uri)\n",
                "\n",
                "print(\"Configuration loaded.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Extract (Fetch Data)\n",
                "Fetch top technology headlines from the US.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def fetch_news(api_key, category=\"technology\", country=\"us\"):\n",
                "    params = {\n",
                "        \"country\": country,\n",
                "        \"category\": category,\n",
                "        \"apiKey\": api_key\n",
                "    }\n",
                "    try:\n",
                "        response = requests.get(BASE_URL, params=params)\n",
                "        response.raise_for_status()\n",
                "        return response.json()\n",
                "    except Exception as e:\n",
                "        print(f\"Error fetching news: {e}\")\n",
                "        return None\n",
                "\n",
                "raw_data = fetch_news(API_KEY)\n",
                "if raw_data and \"articles\" in raw_data:\n",
                "    print(f\"Fetched {len(raw_data['articles'])} articles.\")\n",
                "else:\n",
                "    print(\"No data fetched.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Transform (Clean Data)\n",
                "Convert to DataFrame and clean up nested JSON (specifically the 'source' column).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if raw_data and \"articles\" in raw_data:\n",
                "    df = pd.DataFrame(raw_data[\"articles\"])\n",
                "    \n",
                "    # Flatten 'source' column (extract 'name')\n",
                "    df['source_name'] = df['source'].apply(lambda x: x.get('name') if isinstance(x, dict) else None)\n",
                "    \n",
                "    # Select relevant columns\n",
                "    cols = ['source_name', 'author', 'title', 'description', 'url', 'publishedAt', 'content']\n",
                "    df_clean = df[cols].copy()\n",
                "    \n",
                "    # Convert publishedAt to datetime\n",
                "    df_clean['publishedAt'] = pd.to_datetime(df_clean['publishedAt'])\n",
                "    \n",
                "    print(\"Data transformed successfully.\")\n",
                "    display(df_clean.head())\n",
                "else:\n",
                "    df_clean = pd.DataFrame()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Load (Save to DB)\n",
                "Load the transformed data into PostgreSQL.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df_clean.empty:\n",
                "    try:\n",
                "        df_clean.to_sql('tech_news', engine, if_exists='replace', index=False)\n",
                "        print(\"Data loaded into table 'tech_news'.\")\n",
                "    except Exception as e:\n",
                "        print(f\"Error loading to DB: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Analysis & Visualization\n",
                "Analyze the data directly from the database.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analysis 1: Top News Sources\n",
                "query_sources = \"\"\"\n",
                "SELECT source_name, COUNT(*) as article_count \n",
                "FROM tech_news \n",
                "GROUP BY source_name \n",
                "ORDER BY article_count DESC \n",
                "LIMIT 10\n",
                "\"\"\"\n",
                "\n",
                "try:\n",
                "    df_sources = pd.read_sql(query_sources, engine)\n",
                "    \n",
                "    import matplotlib.pyplot as plt\n",
                "    import seaborn as sns\n",
                "\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    sns.barplot(x='article_count', y='source_name', data=df_sources, palette='coolwarm')\n",
                "    plt.title('Top 10 Tech News Sources')\n",
                "    plt.xlabel('Number of Articles')\n",
                "    plt.ylabel('Source')\n",
                "    plt.show()\n",
                "except Exception as e:\n",
                "    print(f\"Analysis failed: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analysis 2: Articles by Hour (Publication Time)\n",
                "query_time = \"\"\"\n",
                "SELECT EXTRACT(HOUR FROM \"publishedAt\") as hour, COUNT(*) as count\n",
                "FROM tech_news\n",
                "GROUP BY hour\n",
                "ORDER BY hour\n",
                "\"\"\"\n",
                "\n",
                "try:\n",
                "    df_time = pd.read_sql(query_time, engine)\n",
                "    \n",
                "    plt.figure(figsize=(10, 5))\n",
                "    sns.lineplot(x='hour', y='count', data=df_time, marker='o')\n",
                "    plt.title('News Publication Frequency by Hour (UTC)')\n",
                "    plt.xlabel('Hour of Day')\n",
                "    plt.ylabel('Number of Articles')\n",
                "    plt.grid(True)\n",
                "    plt.xticks(range(0, 24))\n",
                "    plt.show()\n",
                "except Exception as e:\n",
                "    print(f\"Time analysis failed: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "This notebook demonstrated a complete ETL pipeline:\n",
                "1.  **Extracted** live data from an external API.\n",
                "2.  **Transformed** nested JSON into a flat, structured format.\n",
                "3.  **Loaded** the clean data into a relational database.\n",
                "4.  **Analyzed** the stored data to derive insights about news sources and timing.\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}